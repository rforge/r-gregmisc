\section{Methods}

\begin{verbatim}
$Id$
\end{verbatim}

  \subsection{The Data}
  
    The data is generated with Gillespie's
    algorithm for stochastic simulation of chemical reactions
    \cite{Gillespie77}. In this paper we present the results for a 
    5-reaction sequence that is sampled at 12, 16, or 25 time points 
    with 3 replicates at each time point. 
<<data, echo=F, eval=T>>=1
# gillespie.out - output from the Gillespie simulation
source('R/getPaperData.R')
source('R/getPaperRates.R')
# trim the Gillespie output
rawdata <- read.table('data/gillespie.out',header=T)[2528:7160,]
# sampling times:
# times12 <- c(16:19,20.5,21,seq(24,39,3))
times16 <- c(16:19,20.5,21,seq(22,40,2))
# times25 <- c(16:19,20.5,21:40)
# generating the MCMC input files, e.g., input16.dat
data <- getPaperData(rawdata,20,times16,npoints=3, varVector=c(50,70,60,40,40))
rates <- getPaperRates(data,1:12,13:48)
temp <- matrix(0,nrow=16,ncol=11)
for (i in 1:16) temp[i,] <- (rates[3*i,]+rates[3*i-1,]+rates[3*i-2,])/3
colnames(temp) <- colnames(rates)
write.table(temp,file="data/input16.dat",row.names=F,quote=F)
@  
    The sequence is
    \begin{reaction} source \yields R1 \yields R2 \yields
      R3 \yields R4 \yields R5 \yields sink \end{reaction}
    and the the equations that were used in the Gillespie simulatiuon
    are
    \begin{chemarray*}
      source &\yields^{k_1}& R1\\
      R1 + E1 &\eqbm^{k_2}_{k_3}& R1E1 \yields^{k_4} R2 + E1\\
      R2 + E2 &\eqbm^{k_5}_{k_6}& R2E2 \yields^{k_7} R3 + E2\\
      R3 + E3 &\eqbm^{k_8}_{k_9}& R3E3 \yields^{k_{10}} R4 + E3\\
      R4 + E4 &\eqbm^{k_{11}}_{k_{12}}& R4E4 \yields^{k_{13}} R5 + E4\\
      R5 &\yields^{k_{14}}& sink
    \end{chemarray*}

    To estimate the kinetic parameters of the enzymes in a sequence of
    reactions, we need to find expressions of the form
    \[
    \text{reaction velocity} = f(\mathit{[substrate],[enzyme]})
    \]
    These expressions can be found by perturbing a reaction network
    and observing the metabolite concentrations as the system relaxes
    back to a steady state. The metabolite concentrations are
    measured, and the velocities are calculated as the
    slopes of the curves of metabolite concentration as functions of
    time.

    For the 5-reaction sequence of reactions 
    the perturbation of $R1$ at $time = 20$ results in the time
    courses plotted in Figure~\ref{pulse}.

<<echo=F,eval=T>>=2
source("R/pulse.R")
rawdata <- read.table("data/rawdata.dat",header=T)
attach(rawdata)
pdf(file="figures/tempDir/pulse.pdf",width=9,height=5)
pulse()
dev.off()
detach(rawdata)
@
    \begin{figure}
      \centering
      \includegraphics[scale=0.5]{figures/tempDir/pulse}
      \caption[Reactant concentrations following a pulse of R1]{Reactant concentrations following a pulse of R1 at
      $time=20$ for the sequence of reactions $R1\rightarrow
      R2\rightarrow R3\rightarrow R4\rightarrow R5\rightarrow sink$.}
      \label{pulse}
    \end{figure}
    For each time point there are 5 values for the reactant
    concentrations and 5 values for the estimated reaction rates.

    The data at each time point was generated by sampling 3 values for
    each reactant from a normal distribution centered on the Gillespie
    output and with a standard deviation of 50. Three sets of time
    points containing 12,16, and 25 points were used.
    The reaction velocities were estimated with the
    \textit{smooth.spline()} function in \textit{R}~\cite{R}. 

  \subsection{Biochemical Models}

    Individual reactions were fit using the Michaelis-Menten
    equation \cite{Michaelis13} for individual enzymes. This is a
    reaction of the form
    \begin{reaction}\label{eqnForm}
      E + S \eqbm^{k_1}_{k_2} ES \yields^{k_3} E + P
    \end{reaction}
    where
    \begin{eqnarray*}
      S &=& \text{substrate concentration}\\
      E &=& \text{free enzyme concentration}\\
      ES &=& \text{concentration of the enzyme-substrate complex}\\
      P &=& \text{product concentration}
    \end{eqnarray*}
    It has been shown \cite{Briggs25} that in a steady state the rate
    of the reaction $v$ is
    \begin{equation}
    v = \frac{V_{max}S}{K_m+S} 
    \end{equation}
    where
    \begin{eqnarray*}
      V_{max} &=& (E+ES)k_3 = \text{maximum reaction velocity}\\[2mm]
      K_m &=& \frac{k_2+k_3}{k_1} = \text{substrate concentration at
      half-maximal velocity}
    \end{eqnarray*}
    This form of the equation is very useful because $v$ and $S$ are
    usually measureable and $V_{max}$ and $K_m$ can be obtained by
    fitting  equation 3 to the data. In contrast, modeling $v$ as a
    function of the individual rate constants is less useful because
    that requires the measurement of the concentration of the
    enzyme-substrate complex which is technically difficult.

    In this application we are dealing with sequences of reactions
    which are not in a steady state, so we cannot use the
    Michaelis-Menten equation directly. Instead, we use equations
    of the form
    \begin{equation}
    v = \frac{aS}{b+S} - \frac{cP}{d+P} 
  \end{equation}
    
    The coefficients $a$, $b$, $c$, and $d$ in the equations can be estimated with data
    obtained following a change in the concentration of one
    of the reactants. For example, four equations
    can be fit to the data plotted in Figure~\ref{pulse}:
    \begin{align*}
      \deriv{R2}{t} &= v_2 = \frac{d_1R1}{d_2 + R1} -
      \frac{d_3R2}{d_4 + R2}\\[5mm]
      \deriv{R3}{t} &= v_3 = \frac{d_3R2}{d_4 + R2} - \frac{d_5R3}{d_6
      + R3}\\[5mm]
      \deriv{R4}{t} &= v_4 = \frac{d_5R3}{d_6 + R3} - \frac{d_7R4}{d_8
      + R4}\\[5mm]
      \deriv{R5}{t} &= v_5 = \frac{d_7R4}{d_8 + R4} - d_9R5
    \end{align*}

\begin{table}
 \begin{center}
    \caption{Rate constants used in the Gillespie simulator}
    \begin{tabular}{c|r}
      rate constant & value \\
      \hline
      $k_1$ & 1.600 \\
      $k_2$ & 0.540 \\
      $k_3$ & 19.500 \\
      $k_4$ & 2.125 \\
      $k_5$ & 0.190 \\
      $k_6$ & 8.460 \\
      $k_7$ & 2.077 \\
      $k_8$ & 0.090 \\
      $k_9$ & 4.560 \\
      $k_{10}$ & 1.400 \\
      $k_{11}$ & 0.106 \\
      $k_{12}$ & 3.670 \\
      $k_{13}$ & 1.640 \\
      $k_{14}$ & 0.400 \\
      \hline
    \end{tabular}
    \label{ki}
  \end{center}
\end{table}

  \subsection{Statistical Models}

    The statistical model of the parameters is 
    the product of a prior distribution and a
    likelihood distribution, where the prior expresses our current
    estimate for the parameter values and the likelihood is the
    probability of the parameters given the data.
  
    The parameters to be estimated, i.e., the reaction rate constants and
    the data standard deviation, are necessarily non-negative and have
    maximum values that are bounded by the physical nature of the
    systems. We model this using
    statistical model for each parameter of the form
    \[
    \frac{3d_i}{\mu_i} \sim \chi_5^2
    \]
    where the $\mu_i$ are the estimates of the parameter values before
    any data are collected. With this distribution, the $d_i$s will
    have a mode of $\mu_i$ and large values will be unlikely. In this situation, $\mu_i \equiv 50$ for
    the rate constants and $\sigma \equiv 2$ for the data standard
    deviation seem appropriate, and are used in the
    priors.
  
    The likelihood is the probability of the
    estimated reaction velocities $v_j$ given the model.
    The error in the velocity estimates is assumed
    to be $N(0,\sigma^2)$ so that the reaction velocities $v_j$ have a
    normal distribution:
    \[
    v_j \sim N(\mu_j,\sigma^2)
    \]
    where
    \[
    \mu_j = \frac{aS_j}{b+S_j} - \frac{cP_j}{d+P_j} 
    \]
    The observed data consist of values for $v_j$, $S_j$, and $P_j$. For
    example, for the 5-reaction model we have
    \begin{align*}
      v_2 &\sim N\left(\frac{d_1R1}{d_2+R1} -
      \frac{d_3R2}{d_4+R2}, \;\; \sigma^2\right)\\
      v_3 &\sim N\left(\frac{d_3R2}{d_4+R2} -
      \frac{d_5R3}{d_6+R3}, \;\; \sigma^2\right)\\
      v_4 &\sim N\left(\frac{d_5R3}{d_6+R3} -
      \frac{d_7R4}{d_8+R4}, \;\; \sigma^2\right)\\
      \intertext{and}
      v_5 &\sim N\left(\frac{d_7R4}{d_8+R4} - d_9R5, \;\; \sigma^2\right)
    \end{align*}
    In this case there are 10 parameters to be estimated: the 9
    coefficients $d_1$ -- $d_9$ and $\sigma^2$.

    \subsubsection{MCMC sampling algorithms}

    The performance of a MCMC simulation
    \cite{Metropolis53,Hastings70} depends heavily on the
    method used to find candidate points to add to the Markov chain
    [$q(\cdot |\cdot)$]. A
    standard proposal distribution for the continuous problem is a
    multivariate normal distribution. However,
    the size of the space to be sampled grows exponentially with the
    number of dimensions and if the joint density is multimodal,
    finding all the modes can be a problem. For this reason proposal
    distributions have been developed that result in more efficient
    sampling than a simple one-component-at-a-time sampler.
    
    Three algorithms are implemented in the Hydra
    library \cite{Hydra}:
     component-wise Metropolis, all-components Metropolis, 
    and Normal Kernel Coupler \cite{Warnes00}.

    The component-wise Metropolis and the all-components Metropolis
    algorithms both operate on single Markov chains. The
    component-wise algorithm (Figure~\ref{1comp}) generates candidate points by
    changing the value of only one component (dimension) of the current point at
    each iteration by sampling from a univariate normal distribution
    centered at the current point.
    The all-components algorithm (Figure~\ref{allComp}) changes all the components
    simultaneously by sampling from a multivariate normal distribution
    centered at the current point.
    \begin{figure}
      \centering
      \subfloat[1-component]{\includegraphics[scale=0.50]{figures/1comp}
      \label{1comp}}
      \qquad
      \subfloat[all-components]{\includegraphics[scale=0.50]{figures/allcomp}
      \label{allComp}}
      \qquad
      \subfloat[NKC]{\includegraphics[scale=0.50]{figures/nkc}\label{nkc}}
      \caption[Movement of Markov chains with the
       Metropolis algorithms]{Movement of Markov chains with the component-wise and
      all-components Metropolis algorithms. Movement in a
      2-dimensional space is illustrated, so each point has 2
      components. The dotted lines are contours of equal probability
      density for the proposal distributions and the dashed lines are
      probabilty contours of the target distribution.}
      \label{1comp_vs_all}
    \end{figure}
    The component-wise Metropolis algorithm has the advantage of
    simplicity but may move very slowly if the components are highly
    correlated. The all-components Metropolis avoids the problems with
    correlation by using a covariance matrix and updating two or more
    components simultaneously but may perform poorly in high
    dimensions. A problem with both of these algorithms
    is that if the component distributions have two or more modes
    separated by areas of low probability, the simulator can get stuck
    in the vicinity of one mode and fail to visit the other. The NKC algorithm
    is designed to avoid this difficulty.
    
    The Normal Kernel Coupler (NKC) algorithm operates on multiple chains, so
    that there are several ``current'' states. The NKC uses a normal
    kernel density estimate as the proposal distribution for choosing candidate
    states. The kernel density estimate is generated using the entire set of
    current points.  Since the algorithm
    uses the entire set of current points it can move over areas of
    low probability in the parameter space, especially if the user takes
    care to seed each mode with a few points in the starting set.

  \section{Convergence}
    
    The MCMC simulations are run until the Markov chains have reached
    stable distributions as assessed by \textit{mcgibbsit()}
    \cite{Warnes00}. \textit{mcgibbsit()} calculates the number of
    iterations necessary to estimate a user-specfied quantile $q$ to
    within $\pm r$ with probability $s$, i.e.,
    \textit{mcgibbsit()} indicates when the MCMC sampler has run long
    enough to provide good confidence interval estimates. The defaults, which are used
    in this paper, are $q=0.025$, $r=0.0125$, and $s=0.95$.
